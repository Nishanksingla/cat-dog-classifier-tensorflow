{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "# import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import json\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "\n",
    "# %matplotlib inline\n",
    "# np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = 224\n",
    "data_file = \"dataset.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_layer(input_data,filter_size,stride_size,pad=\"SAME\",name=\"conv\",weight_name=\"W1\",bias_name=\"b1\"):\n",
    "    print(\"creating layer :\"+name)\n",
    "    with tf.name_scope(name):\n",
    "        W = tf.get_variable(weight_name, shape = filter_size, initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.get_variable(bias_name, shape = [filter_size[-1]], initializer = tf.constant_initializer(0.0))\n",
    "        \n",
    "        conv = tf.nn.conv2d(input_data, W, strides=stride_size, padding=pad)\n",
    "        out = tf.nn.bias_add(conv, biases)\n",
    "        act = tf.nn.relu(out)\n",
    "        tf.summary.histogram(\"biases\", biases)\n",
    "        tf.summary.histogram(\"weights\", W)\n",
    "        tf.summary.histogram(\"activations\", act)\n",
    "        return act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vggnet_v1(input_data):\n",
    "    print(\"creating model\")\n",
    "    output=[]\n",
    "    layer_input = input_data\n",
    "    \n",
    "    print(\"reading vgg16 json file\")\n",
    "    vgg = json.load(open(\"vgg16.json\"),object_pairs_hook=OrderedDict)\n",
    "   \n",
    "    for index,layer in enumerate(vgg):\n",
    "        if \"conv\" in layer:\n",
    "            output = conv_layer(layer_input,vgg[layer][\"weights\"],vgg[layer][\"stride\"],vgg[layer][\"pad\"],layer,\"weight\"+str(index),\"bias\"+str(index))\n",
    "        elif \"pool\" in layer:\n",
    "            output = tf.nn.max_pool(layer_input, ksize=vgg[layer][\"ksize\"], strides=vgg[layer][\"strides\"], padding=vgg[layer][\"padding\"],name=layer)\n",
    "        layer_input = output\n",
    "    \n",
    "    P3 = tf.contrib.layers.flatten(output)\n",
    "    \n",
    "    fc6 = tf.contrib.layers.fully_connected(P3,4096,biases_initializer=tf.constant_initializer(1.0), scope=\"fc6\")\n",
    "    tf.summary.histogram(\"fc6/relu\", fc6)\n",
    "    \n",
    "    dropout1 = tf.layers.dropout(inputs=fc6, rate=0.5)\n",
    "    \n",
    "    fc7 = tf.contrib.layers.fully_connected(dropout1,4096,biases_initializer=tf.constant_initializer(1.0), scope=\"fc7\")\n",
    "    tf.summary.histogram(\"fc7/relu\", fc7)\n",
    "    \n",
    "    dropout2 = tf.layers.dropout(inputs=fc7, rate=0.5)\n",
    "    \n",
    "    fc8 = tf.contrib.layers.fully_connected(dropout2,2, biases_initializer=tf.constant_initializer(1.0), activation_fn=None, scope=\"fc8\")\n",
    "    tf.summary.histogram(\"fc8\", fc8)\n",
    "    \n",
    "    \n",
    "    print(\"model completed.\")\n",
    "    ##NEED FULLY CONNECTED LAYER\n",
    "    return fc8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vggnet_v2(input_data):\n",
    "    \n",
    "    # conv1_1\n",
    "    conv1_1 = conv_layer(input_data,[3,3,3,64],[1, 1, 1, 1],\"SAME\",\"conv1_1\",\"weight1\")\n",
    "\n",
    "    # conv1_2\n",
    "    conv1_2 = conv_layer(conv1_1,[3,3,64,64],[1, 1, 1, 1],\"SAME\",\"conv1_2\",\"weight2\")\n",
    "        \n",
    "    # pool1\n",
    "    pool1 = tf.nn.max_pool(conv1_2,ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],padding=\"SAME\",name='pool1')\n",
    "        \n",
    "    # conv2_1\n",
    "    conv2_1 = conv_layer(pool1,[3, 3, 64, 128],[1, 1, 1, 1],\"SAME\",\"conv2_1\",\"weight3\")\n",
    "        \n",
    "    # conv2_2\n",
    "    conv2_2 = conv_layer(conv2_1,[3,3,128,128],[1, 1, 1, 1],\"SAME\",\"conv2_2\",\"weight4\")\n",
    "\n",
    "    # pool2\n",
    "    pool2 = tf.nn.max_pool(conv2_2,ksize=[1, 2, 2, 1],strides=[1, 2, 2, 1],padding='SAME',name='pool2')\n",
    "\n",
    "    # conv3_1\n",
    "    conv3_1 = conv_layer(pool2,[3,3,128,256],[1, 1, 1, 1],\"SAME\",\"conv3_1\",\"weight5\")\n",
    "    \n",
    "    # conv3_2\n",
    "    conv3_2 = conv_layer(conv3_1,[3,3,256,256],[1, 1, 1, 1],\"SAME\",\"conv3_2\",\"weight6\")\n",
    "    \n",
    "    # conv3_3\n",
    "    conv3_3 = conv_layer(conv3_2,[3,3,256,256],[1, 1, 1, 1],\"SAME\",\"conv3_3\",\"weight7\")\n",
    "\n",
    "    # pool3\n",
    "    pool3 = tf.nn.max_pool(conv3_3,ksize=[1, 2, 2, 1],strides=[1, 2, 2, 1],padding='SAME',name='pool3')\n",
    "\n",
    "    # conv4_1\n",
    "    conv4_1 = conv_layer(pool3,[3, 3, 256, 512],[1, 1, 1, 1],\"SAME\",\"conv4_1\",\"weight8\")\n",
    "        \n",
    "    # conv4_2\n",
    "    conv4_2 = conv_layer(conv4_1,[3, 3, 512, 512],[1, 1, 1, 1],\"SAME\",\"conv4_2\",\"weight9\")\n",
    "\n",
    "    # conv4_3\n",
    "    conv4_3 = conv_layer(conv4_2,[3, 3, 512, 512],[1, 1, 1, 1],\"SAME\",\"conv4_3\",\"weight10\")\n",
    "\n",
    "    # pool4\n",
    "    pool4 = tf.nn.max_pool(conv4_3,ksize=[1, 2, 2, 1],strides=[1, 2, 2, 1],padding='SAME',name='pool4')\n",
    "\n",
    "    # conv5_1\n",
    "    conv5_1 = conv_layer(pool4,[3, 3, 512, 512],[1, 1, 1, 1],\"SAME\",\"conv5_1\",\"weight11\")\n",
    "   \n",
    "    # conv5_2\n",
    "    conv5_2 = conv_layer(conv5_1,[3, 3, 512, 512],[1, 1, 1, 1],\"SAME\",\"conv5_2\",\"weight12\")\n",
    "\n",
    "    # conv5_3\n",
    "    conv5_3 = conv_layer(conv5_2,[3, 3, 512, 512],[1, 1, 1, 1],\"SAME\",\"conv5_3\",\"weight13\")\n",
    "\n",
    "    # pool5\n",
    "    pool5 = tf.nn.max_pool(conv5_3, ksize=[1, 2, 2, 1],strides=[1, 2, 2, 1],padding='SAME',name='pool5')\n",
    "    \n",
    "    flatten = tf.contrib.layers.flatten(pool5)\n",
    "    print(\"flatten\")\n",
    "    print(flatten)\n",
    "    \n",
    "    fc6 = tf.contrib.layers.fully_connected(flatten,4096,scope=\"fc6\")\n",
    "    tf.summary.histogram(\"fc6/relu\", fc6)\n",
    "    \n",
    "#     dropout1 = tf.layers.dropout(inputs=fc6, rate=0.5)\n",
    "    \n",
    "    fc7 = tf.contrib.layers.fully_connected(fc6,4096,scope=\"fc7\")\n",
    "    tf.summary.histogram(\"fc7/relu\", fc7)\n",
    "    \n",
    "#     dropout = tf.layers.dropout(inputs=fc7, rate=0.5)\n",
    "    \n",
    "    fc8 = tf.contrib.layers.fully_connected(fc7,2,activation_fn=None,scope=\"fc8\")\n",
    "    tf.summary.histogram(\"fc8\", fc8)\n",
    "    print(\"fc8:\")\n",
    "    print(fc8)\n",
    "    print(\"model completed.\")\n",
    "    return fc8\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vggnet_v3(images):\n",
    "    \n",
    "    # conv1_1\n",
    "    with tf.name_scope('conv1_1') as scope:\n",
    "        kernel = tf.Variable(tf.truncated_normal([3, 3, 3, 64], dtype=tf.float32,\n",
    "                                                 stddev=1e-1), name='weights')\n",
    "        conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = tf.Variable(tf.constant(0.0, shape=[64], dtype=tf.float32),\n",
    "                             trainable=True, name='biases')\n",
    "        out = tf.nn.bias_add(conv, biases)\n",
    "        conv1_1 = tf.nn.relu(out, name=scope)\n",
    "        \n",
    "\n",
    "    # conv1_2\n",
    "    with tf.name_scope('conv1_2') as scope:\n",
    "        kernel = tf.Variable(tf.truncated_normal([3, 3, 64, 64], dtype=tf.float32,\n",
    "                                                 stddev=1e-1), name='weights')\n",
    "        conv = tf.nn.conv2d(conv1_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = tf.Variable(tf.constant(0.0, shape=[64], dtype=tf.float32),\n",
    "                             trainable=True, name='biases')\n",
    "        out = tf.nn.bias_add(conv, biases)\n",
    "        conv1_2 = tf.nn.relu(out, name=scope)\n",
    "        \n",
    "\n",
    "    # pool1\n",
    "    pool1 = tf.nn.max_pool(conv1_2,\n",
    "                           ksize=[1, 2, 2, 1],\n",
    "                           strides=[1, 2, 2, 1],\n",
    "                           padding='SAME',\n",
    "                           name='pool1')\n",
    "\n",
    "    # conv2_1\n",
    "    with tf.name_scope('conv2_1') as scope:\n",
    "        kernel = tf.Variable(tf.truncated_normal([3, 3, 64, 128], dtype=tf.float32,\n",
    "                                                 stddev=1e-1), name='weights')\n",
    "        conv = tf.nn.conv2d(pool1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = tf.Variable(tf.constant(0.0, shape=[128], dtype=tf.float32),\n",
    "                             trainable=True, name='biases')\n",
    "        out = tf.nn.bias_add(conv, biases)\n",
    "        conv2_1 = tf.nn.relu(out, name=scope)\n",
    "        \n",
    "\n",
    "    # conv2_2\n",
    "    with tf.name_scope('conv2_2') as scope:\n",
    "        kernel = tf.Variable(tf.truncated_normal([3, 3, 128, 128], dtype=tf.float32,\n",
    "                                                 stddev=1e-1), name='weights')\n",
    "        conv = tf.nn.conv2d(conv2_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = tf.Variable(tf.constant(0.0, shape=[128], dtype=tf.float32),\n",
    "                             trainable=True, name='biases')\n",
    "        out = tf.nn.bias_add(conv, biases)\n",
    "        conv2_2 = tf.nn.relu(out, name=scope)\n",
    "        \n",
    "\n",
    "    # pool2\n",
    "    pool2 = tf.nn.max_pool(conv2_2,\n",
    "                           ksize=[1, 2, 2, 1],\n",
    "                           strides=[1, 2, 2, 1],\n",
    "                           padding='SAME',\n",
    "                           name='pool2')\n",
    "\n",
    "    # conv3_1\n",
    "    with tf.name_scope('conv3_1') as scope:\n",
    "        kernel = tf.Variable(tf.truncated_normal([3, 3, 128, 256], dtype=tf.float32,\n",
    "                                                 stddev=1e-1), name='weights')\n",
    "        conv = tf.nn.conv2d(pool2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32),\n",
    "                             trainable=True, name='biases')\n",
    "        out = tf.nn.bias_add(conv, biases)\n",
    "        conv3_1 = tf.nn.relu(out, name=scope)\n",
    "        \n",
    "\n",
    "    # conv3_2\n",
    "    with tf.name_scope('conv3_2') as scope:\n",
    "        kernel = tf.Variable(tf.truncated_normal([3, 3, 256, 256], dtype=tf.float32,\n",
    "                                                 stddev=1e-1), name='weights')\n",
    "        conv = tf.nn.conv2d(conv3_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32),\n",
    "                             trainable=True, name='biases')\n",
    "        out = tf.nn.bias_add(conv, biases)\n",
    "        conv3_2 = tf.nn.relu(out, name=scope)\n",
    "        \n",
    "\n",
    "    # conv3_3\n",
    "    with tf.name_scope('conv3_3') as scope:\n",
    "        kernel = tf.Variable(tf.truncated_normal([3, 3, 256, 256], dtype=tf.float32,\n",
    "                                                 stddev=1e-1), name='weights')\n",
    "        conv = tf.nn.conv2d(conv3_2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32),\n",
    "                             trainable=True, name='biases')\n",
    "        out = tf.nn.bias_add(conv, biases)\n",
    "        conv3_3 = tf.nn.relu(out, name=scope)\n",
    "        \n",
    "\n",
    "    # pool3\n",
    "    pool3 = tf.nn.max_pool(conv3_3,\n",
    "                           ksize=[1, 2, 2, 1],\n",
    "                           strides=[1, 2, 2, 1],\n",
    "                           padding='SAME',\n",
    "                           name='pool3')\n",
    "\n",
    "    # conv4_1\n",
    "    with tf.name_scope('conv4_1') as scope:\n",
    "        kernel = tf.Variable(tf.truncated_normal([3, 3, 256, 512], dtype=tf.float32,\n",
    "                                                 stddev=1e-1), name='weights')\n",
    "        conv = tf.nn.conv2d(pool3, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                             trainable=True, name='biases')\n",
    "        out = tf.nn.bias_add(conv, biases)\n",
    "        conv4_1 = tf.nn.relu(out, name=scope)\n",
    "        \n",
    "\n",
    "    # conv4_2\n",
    "    with tf.name_scope('conv4_2') as scope:\n",
    "        kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                 stddev=1e-1), name='weights')\n",
    "        conv = tf.nn.conv2d(conv4_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                             trainable=True, name='biases')\n",
    "        out = tf.nn.bias_add(conv, biases)\n",
    "        conv4_2 = tf.nn.relu(out, name=scope)\n",
    "        \n",
    "\n",
    "    # conv4_3\n",
    "    with tf.name_scope('conv4_3') as scope:\n",
    "        kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                 stddev=1e-1), name='weights')\n",
    "        conv = tf.nn.conv2d(conv4_2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                             trainable=True, name='biases')\n",
    "        out = tf.nn.bias_add(conv, biases)\n",
    "        conv4_3 = tf.nn.relu(out, name=scope)\n",
    "        \n",
    "\n",
    "    # pool4\n",
    "    pool4 = tf.nn.max_pool(conv4_3,\n",
    "                           ksize=[1, 2, 2, 1],\n",
    "                           strides=[1, 2, 2, 1],\n",
    "                           padding='SAME',\n",
    "                           name='pool4')\n",
    "\n",
    "    # conv5_1\n",
    "    with tf.name_scope('conv5_1') as scope:\n",
    "        kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                 stddev=1e-1), name='weights')\n",
    "        conv = tf.nn.conv2d(pool4, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                             trainable=True, name='biases')\n",
    "        out = tf.nn.bias_add(conv, biases)\n",
    "        conv5_1 = tf.nn.relu(out, name=scope)\n",
    "        \n",
    "\n",
    "    # conv5_2\n",
    "    with tf.name_scope('conv5_2') as scope:\n",
    "        kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                 stddev=1e-1), name='weights')\n",
    "        conv = tf.nn.conv2d(conv5_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                             trainable=True, name='biases')\n",
    "        out = tf.nn.bias_add(conv, biases)\n",
    "        conv5_2 = tf.nn.relu(out, name=scope)\n",
    "        \n",
    "\n",
    "    # conv5_3\n",
    "    with tf.name_scope('conv5_3') as scope:\n",
    "        kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                 stddev=1e-1), name='weights')\n",
    "        conv = tf.nn.conv2d(conv5_2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                             trainable=True, name='biases')\n",
    "        out = tf.nn.bias_add(conv, biases)\n",
    "        conv5_3 = tf.nn.relu(out, name=scope)\n",
    "        \n",
    "\n",
    "    # pool5\n",
    "    pool5 = tf.nn.max_pool(conv5_3,\n",
    "                           ksize=[1, 2, 2, 1],\n",
    "                           strides=[1, 2, 2, 1],\n",
    "                           padding='SAME',\n",
    "                           name='pool4')\n",
    "    \n",
    "    \n",
    "    # fc1\n",
    "    with tf.name_scope('fc1') as scope:\n",
    "        shape = int(np.prod(pool5.get_shape()[1:]))\n",
    "        fc1w = tf.Variable(tf.truncated_normal([shape, 4096],\n",
    "                                                     dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "        fc1b = tf.Variable(tf.constant(1.0, shape=[4096], dtype=tf.float32),\n",
    "                             trainable=True, name='biases')\n",
    "        pool5_flat = tf.reshape(pool5, [-1, shape])\n",
    "        fc1l = tf.nn.bias_add(tf.matmul(pool5_flat, fc1w), fc1b)\n",
    "        fc1 = tf.nn.relu(fc1l)\n",
    "\n",
    "\n",
    "    # fc2\n",
    "    with tf.name_scope('fc2') as scope:\n",
    "        fc2w = tf.Variable(tf.truncated_normal([4096, 4096],\n",
    "                                                     dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "        fc2b = tf.Variable(tf.constant(1.0, shape=[4096], dtype=tf.float32),\n",
    "                             trainable=True, name='biases')\n",
    "        fc2l = tf.nn.bias_add(tf.matmul(fc1, fc2w), fc2b)\n",
    "        fc2 = tf.nn.relu(fc2l)\n",
    "\n",
    "\n",
    "    # fc3\n",
    "    with tf.name_scope('fc3') as scope:\n",
    "        fc3w = tf.Variable(tf.truncated_normal([4096, 2],\n",
    "                                                     dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "        fc3b = tf.Variable(tf.constant(1.0, shape=[2], dtype=tf.float32),\n",
    "                             trainable=True, name='biases')\n",
    "        fc3l = tf.nn.bias_add(tf.matmul(fc2, fc3w), fc3b)\n",
    "#         fc3 = tf.nn.relu(fc3l)\n",
    "\n",
    "    return fc3l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    newData=[]\n",
    "    labels=[]\n",
    "    print(\"preparing data....\")\n",
    "    for sample in data:\n",
    "        img_path,label = sample.strip().split(\" \")\n",
    "        img = Image.open(img_path)\n",
    "        img = img.resize((IMG_SIZE,IMG_SIZE))\n",
    "        img = np.array(img)\n",
    "        img = img/255\n",
    "        newData.append(img)\n",
    "        if \"cat\" in img_path:\n",
    "            labels.append(np.array([1,0]))\n",
    "        elif \"dog\" in img_path:\n",
    "            labels.append(np.array([0,1]))\n",
    "    print(\"preparing data completed.\")\n",
    "    return np.array(newData),np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "preparing data....\n",
      "preparing data completed.\n",
      "preparing data....\n",
      "preparing data completed.\n"
     ]
    }
   ],
   "source": [
    "f = open(data_file,\"r\")\n",
    "data = f.readlines()\n",
    "random.shuffle(data)\n",
    "print(len(data))\n",
    "train_data = data[:20000]\n",
    "train_X, train_Y = prepare_data(train_data)\n",
    "val_data = data[20000:]\n",
    "val_X, val_Y = prepare_data(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating model\n",
      "reading vgg16 json file\n",
      "creating layer :conv1_1\n",
      "creating layer :conv1_2\n",
      "creating layer :conv2_1\n",
      "creating layer :conv2_2\n",
      "creating layer :conv3_1\n",
      "creating layer :conv3_2\n",
      "creating layer :conv3_3\n",
      "creating layer :conv4_1\n",
      "creating layer :conv4_2\n",
      "creating layer :conv4_3\n",
      "creating layer :conv5_1\n",
      "creating layer :conv5_2\n",
      "creating layer :conv5_3\n",
      "model completed.\n",
      "optimizer set\n",
      "accuracy set\n",
      "session created.\n",
      "writing tensorboard\n",
      "writer added to graph\n",
      "processing epoch 0\n",
      "total number of batches in 1 epoch: 625.0\n",
      "Batch:1.0\n",
      "temp_loss: 0.735543\n",
      "Batch:2.0\n",
      "temp_loss: 3.7042e+12\n",
      "Batch:3.0\n",
      "temp_loss: 766.059\n",
      "Batch:4.0\n",
      "temp_loss: 44.4433\n",
      "Batch:5.0\n",
      "temp_loss: 11.7322\n",
      "Batch:6.0\n",
      "temp_loss: 13.0142\n",
      "Batch:7.0\n",
      "temp_loss: 28.4219\n",
      "Batch:8.0\n",
      "temp_loss: 31.5956\n",
      "Batch:9.0\n",
      "temp_loss: 25.554\n",
      "Batch:10.0\n",
      "temp_loss: 30.5473\n",
      "Batch:11.0\n",
      "temp_loss: 14.9519\n",
      "Batch:12.0\n",
      "temp_loss: 7.63021\n",
      "Batch:13.0\n",
      "temp_loss: 5.13941\n",
      "Batch:14.0\n",
      "temp_loss: 10.1688\n",
      "Batch:15.0\n",
      "temp_loss: 16.1361\n",
      "Batch:16.0\n",
      "temp_loss: 8.48658\n",
      "Batch:17.0\n",
      "temp_loss: 6.62137\n",
      "Batch:18.0\n",
      "temp_loss: 1.20068\n",
      "Batch:19.0\n",
      "temp_loss: 7.53884\n",
      "Batch:20.0\n",
      "temp_loss: 7.84934\n",
      "Batch:21.0\n",
      "temp_loss: 11.9725\n",
      "Batch:22.0\n",
      "temp_loss: 13.693\n",
      "Batch:23.0\n",
      "temp_loss: 12.1496\n",
      "Batch:24.0\n",
      "temp_loss: 6.15717\n",
      "Batch:25.0\n",
      "temp_loss: 1.4826\n",
      "Batch:26.0\n",
      "temp_loss: 7.00803\n",
      "Batch:27.0\n",
      "temp_loss: 10.3414\n",
      "Batch:28.0\n",
      "temp_loss: 13.6433\n",
      "Batch:29.0\n",
      "temp_loss: 13.5242\n",
      "Batch:30.0\n",
      "temp_loss: 9.86411\n",
      "Batch:31.0\n",
      "temp_loss: 3.41746\n",
      "Batch:32.0\n",
      "temp_loss: 2.83178\n",
      "Batch:33.0\n",
      "temp_loss: 5.95629\n",
      "Batch:34.0\n",
      "temp_loss: 11.6696\n",
      "Batch:35.0\n",
      "temp_loss: 8.9388\n",
      "Batch:36.0\n",
      "temp_loss: 7.74943\n",
      "Batch:37.0\n",
      "temp_loss: 3.71155\n",
      "Batch:38.0\n",
      "temp_loss: 0.77328\n",
      "Batch:39.0\n",
      "temp_loss: 4.79028\n",
      "Batch:40.0\n",
      "temp_loss: 6.55031\n",
      "Batch:41.0\n",
      "temp_loss: 3.47271\n",
      "validating...\n",
      "validation loss:\n",
      "0.71532394886\n",
      "validation accuracy: \n",
      "0.49399998188\n",
      "Batch:42.0\n",
      "temp_loss: 0.725402\n",
      "Batch:43.0\n",
      "temp_loss: 2.97748\n",
      "Batch:44.0\n",
      "temp_loss: 4.24964\n",
      "Batch:45.0\n",
      "temp_loss: 1.37307\n",
      "Batch:46.0\n",
      "temp_loss: 2.13645\n",
      "Batch:47.0\n",
      "temp_loss: 6.07121\n",
      "Batch:48.0\n",
      "temp_loss: 3.16437\n",
      "Batch:49.0\n",
      "temp_loss: 0.692541\n",
      "Batch:50.0\n",
      "temp_loss: 2.42904\n",
      "Batch:51.0\n",
      "temp_loss: 5.01052\n",
      "Batch:52.0\n",
      "temp_loss: 2.24095\n",
      "Batch:53.0\n",
      "temp_loss: 1.16341\n",
      "Batch:54.0\n",
      "temp_loss: 2.335\n",
      "Batch:55.0\n",
      "temp_loss: 1.85351\n",
      "Batch:56.0\n",
      "temp_loss: 1.6806\n",
      "Batch:57.0\n",
      "temp_loss: 2.55665\n",
      "Batch:58.0\n",
      "temp_loss: 0.697587\n",
      "Batch:59.0\n",
      "temp_loss: 1.41837\n",
      "Batch:60.0\n",
      "temp_loss: 1.64419\n",
      "Batch:61.0\n",
      "temp_loss: 1.33725\n",
      "validating...\n",
      "validation loss:\n",
      "2.21611945033\n",
      "validation accuracy: \n",
      "0.49399998188\n",
      "Batch:62.0\n",
      "temp_loss: 2.18999\n",
      "Batch:63.0\n",
      "temp_loss: 3.18907\n",
      "Batch:64.0\n",
      "temp_loss: 1.32485\n",
      "Batch:65.0\n",
      "temp_loss: 1.44421\n",
      "Batch:66.0\n",
      "temp_loss: 1.87411\n",
      "Batch:67.0\n",
      "temp_loss: 0.711789\n",
      "Batch:68.0\n",
      "temp_loss: 1.42844\n",
      "Batch:69.0\n",
      "temp_loss: 1.63843\n",
      "Batch:70.0\n",
      "temp_loss: 0.73827\n",
      "Batch:71.0\n",
      "temp_loss: 2.09456\n",
      "Batch:72.0\n",
      "temp_loss: 1.42079\n",
      "Batch:73.0\n",
      "temp_loss: 1.03872\n",
      "Batch:74.0\n",
      "temp_loss: 0.947946\n",
      "Batch:75.0\n",
      "temp_loss: 0.717145\n",
      "Batch:76.0\n",
      "temp_loss: 0.589791\n",
      "Batch:77.0\n",
      "temp_loss: 1.37046\n",
      "Batch:78.0\n",
      "temp_loss: 1.13406\n",
      "Batch:79.0\n",
      "temp_loss: 1.35085\n",
      "Batch:80.0\n",
      "temp_loss: 0.808105\n",
      "Batch:81.0\n",
      "temp_loss: 1.06557\n",
      "validating...\n",
      "validation loss:\n",
      "2.30825579047\n",
      "validation accuracy: \n",
      "0.505999985337\n",
      "Batch:82.0\n",
      "temp_loss: 2.77243\n",
      "Batch:83.0\n",
      "temp_loss: 0.831196\n",
      "Batch:84.0\n",
      "temp_loss: 2.73097\n",
      "Batch:85.0\n",
      "temp_loss: 2.44105\n",
      "Batch:86.0\n",
      "temp_loss: 0.872639\n",
      "Batch:87.0\n",
      "temp_loss: 2.39778\n",
      "Batch:88.0\n",
      "temp_loss: 1.78441\n",
      "Batch:89.0\n",
      "temp_loss: 0.703489\n",
      "Batch:90.0\n",
      "temp_loss: 1.55017\n",
      "Batch:91.0\n",
      "temp_loss: 1.55558\n",
      "Batch:92.0\n",
      "temp_loss: 0.690581\n",
      "Batch:93.0\n",
      "temp_loss: 2.26853\n",
      "Batch:94.0\n",
      "temp_loss: 1.79332\n",
      "Batch:95.0\n",
      "temp_loss: 0.943789\n",
      "Batch:96.0\n",
      "temp_loss: 1.20528\n",
      "Batch:97.0\n",
      "temp_loss: 0.781693\n",
      "Batch:98.0\n",
      "temp_loss: 1.84305\n",
      "Batch:99.0\n",
      "temp_loss: 0.814761\n",
      "Batch:100.0\n",
      "temp_loss: 0.776912\n",
      "Batch:101.0\n",
      "temp_loss: 1.47368\n",
      "validating...\n",
      "validation loss:\n",
      "0.718758827448\n",
      "validation accuracy: \n",
      "0.49399998188\n",
      "Batch:102.0\n",
      "temp_loss: 0.689246\n",
      "Batch:103.0\n",
      "temp_loss: 0.964142\n",
      "Batch:104.0\n",
      "temp_loss: 1.09138\n",
      "Batch:105.0\n",
      "temp_loss: 0.881931\n",
      "Batch:106.0\n",
      "temp_loss: 0.789074\n",
      "Batch:107.0\n",
      "temp_loss: 0.826831\n",
      "Batch:108.0\n",
      "temp_loss: 0.727891\n",
      "Batch:109.0\n",
      "temp_loss: 0.710768\n",
      "Batch:110.0\n",
      "temp_loss: 0.992437\n",
      "Batch:111.0\n",
      "temp_loss: 1.22183\n",
      "Batch:112.0\n",
      "temp_loss: 0.833261\n",
      "Batch:113.0\n",
      "temp_loss: 1.01852\n",
      "Batch:114.0\n",
      "temp_loss: 1.62358\n",
      "Batch:115.0\n",
      "temp_loss: 0.694254\n",
      "Batch:116.0\n",
      "temp_loss: 1.87225\n",
      "Batch:117.0\n",
      "temp_loss: 0.917019\n",
      "Batch:118.0\n",
      "temp_loss: 0.999233\n",
      "Batch:119.0\n",
      "temp_loss: 0.735954\n",
      "Batch:120.0\n",
      "temp_loss: 1.27756\n",
      "Batch:121.0\n",
      "temp_loss: 0.677165\n",
      "validating...\n",
      "validation loss:\n",
      "1.49088049352\n",
      "validation accuracy: \n",
      "0.49399998188\n",
      "Batch:122.0\n",
      "temp_loss: 1.91661\n",
      "Batch:123.0\n",
      "temp_loss: 0.836034\n",
      "Batch:124.0\n",
      "temp_loss: 0.70454\n",
      "Batch:125.0\n",
      "temp_loss: 0.686933\n",
      "Batch:126.0\n",
      "temp_loss: 0.909303\n",
      "Batch:127.0\n",
      "temp_loss: 0.709481\n",
      "Batch:128.0\n",
      "temp_loss: 1.09464\n",
      "Batch:129.0\n",
      "temp_loss: 0.979258\n",
      "Batch:130.0\n",
      "temp_loss: 0.922543\n",
      "Batch:131.0\n",
      "temp_loss: 1.44864\n",
      "Batch:132.0\n",
      "temp_loss: 0.859404\n",
      "Batch:133.0\n",
      "temp_loss: 1.25629\n",
      "Batch:134.0\n",
      "temp_loss: 1.38366\n",
      "Batch:135.0\n",
      "temp_loss: 0.996269\n",
      "Batch:136.0\n",
      "temp_loss: 0.865202\n",
      "Batch:137.0\n",
      "temp_loss: 0.694797\n",
      "Batch:138.0\n",
      "temp_loss: 1.1546\n",
      "Batch:139.0\n",
      "temp_loss: 1.35186\n",
      "Batch:140.0\n",
      "temp_loss: 0.945468\n",
      "Batch:141.0\n",
      "temp_loss: 1.34133\n",
      "validating...\n",
      "validation loss:\n",
      "0.702571517229\n",
      "validation accuracy: \n",
      "0.505999985337\n",
      "Batch:142.0\n",
      "temp_loss: 0.723138\n",
      "Batch:143.0\n",
      "temp_loss: 2.04171\n",
      "Batch:144.0\n",
      "temp_loss: 0.835345\n",
      "Batch:145.0\n",
      "temp_loss: 1.56042\n",
      "Batch:146.0\n",
      "temp_loss: 0.935043\n",
      "Batch:147.0\n",
      "temp_loss: 1.27055\n",
      "Batch:148.0\n",
      "temp_loss: 0.916455\n",
      "Batch:149.0\n",
      "temp_loss: 1.17097\n",
      "Batch:150.0\n",
      "temp_loss: 0.75071\n",
      "Batch:151.0\n",
      "temp_loss: 1.09335\n",
      "Batch:152.0\n",
      "temp_loss: 0.6899\n",
      "Batch:153.0\n",
      "temp_loss: 0.791129\n",
      "Batch:154.0\n",
      "temp_loss: 0.732296\n",
      "Batch:155.0\n",
      "temp_loss: 0.708858\n",
      "Batch:156.0\n",
      "temp_loss: 0.713718\n",
      "Batch:157.0\n",
      "temp_loss: 0.960841\n",
      "Batch:158.0\n",
      "temp_loss: 1.07353\n",
      "Batch:159.0\n",
      "temp_loss: 0.749122\n",
      "Batch:160.0\n",
      "temp_loss: 1.01438\n",
      "Batch:161.0\n",
      "temp_loss: 0.702106\n",
      "validating...\n",
      "validation loss:\n",
      "0.855875806808\n",
      "validation accuracy: \n",
      "0.505999985337\n",
      "Batch:162.0\n",
      "temp_loss: 1.05045\n",
      "Batch:163.0\n",
      "temp_loss: 0.8859\n",
      "Batch:164.0\n",
      "temp_loss: 0.862826\n",
      "Batch:165.0\n",
      "temp_loss: 1.16006\n",
      "Batch:166.0\n",
      "temp_loss: 1.08518\n",
      "Batch:167.0\n",
      "temp_loss: 0.974333\n",
      "Batch:168.0\n",
      "temp_loss: 0.698001\n",
      "Batch:169.0\n",
      "temp_loss: 0.881167\n",
      "Batch:170.0\n",
      "temp_loss: 0.729899\n",
      "Batch:171.0\n",
      "temp_loss: 0.949061\n",
      "Batch:172.0\n",
      "temp_loss: 0.700862\n",
      "Batch:173.0\n",
      "temp_loss: 0.837883\n",
      "Batch:174.0\n",
      "temp_loss: 0.699449\n",
      "Batch:175.0\n",
      "temp_loss: 0.846431\n",
      "Batch:176.0\n",
      "temp_loss: 0.700744\n",
      "Batch:177.0\n",
      "temp_loss: 0.831521\n",
      "Batch:178.0\n",
      "temp_loss: 0.884699\n",
      "Batch:179.0\n",
      "temp_loss: 0.918242\n",
      "Batch:180.0\n",
      "temp_loss: 0.933963\n",
      "Batch:181.0\n",
      "temp_loss: 1.12424\n",
      "validating...\n",
      "validation loss:\n",
      "0.908509703875\n",
      "validation accuracy: \n",
      "0.49399998188\n",
      "Batch:182.0\n",
      "temp_loss: 0.900512\n",
      "Batch:183.0\n",
      "temp_loss: 1.12111\n",
      "Batch:184.0\n",
      "temp_loss: 1.3014\n",
      "Batch:185.0\n",
      "temp_loss: 1.17878\n",
      "Batch:186.0\n",
      "temp_loss: 1.25285\n",
      "Batch:187.0\n",
      "temp_loss: 1.87767\n",
      "Batch:188.0\n",
      "temp_loss: 0.686854\n",
      "Batch:189.0\n",
      "temp_loss: 2.0253\n",
      "Batch:190.0\n",
      "temp_loss: 1.07986\n",
      "Batch:191.0\n",
      "temp_loss: 2.2207\n",
      "Batch:192.0\n",
      "temp_loss: 1.47968\n",
      "Batch:193.0\n",
      "temp_loss: 0.646\n",
      "Batch:194.0\n",
      "temp_loss: 2.83774\n",
      "Batch:195.0\n",
      "temp_loss: 0.812091\n",
      "Batch:196.0\n",
      "temp_loss: 1.41558\n",
      "Batch:197.0\n",
      "temp_loss: 0.94881\n",
      "Batch:198.0\n",
      "temp_loss: 0.687335\n",
      "Batch:199.0\n",
      "temp_loss: 1.17764\n",
      "Batch:200.0\n",
      "temp_loss: 0.763514\n",
      "Batch:201.0\n",
      "temp_loss: 0.786321\n",
      "validating...\n",
      "validation loss:\n",
      "1.64453164697\n",
      "validation accuracy: \n",
      "0.49399998188\n",
      "Batch:202.0\n",
      "temp_loss: 1.72454\n",
      "Batch:203.0\n",
      "temp_loss: 0.67333\n",
      "Batch:204.0\n",
      "temp_loss: 2.00356\n",
      "Batch:205.0\n",
      "temp_loss: 0.870573\n",
      "Batch:206.0\n",
      "temp_loss: 1.66692\n",
      "Batch:207.0\n",
      "temp_loss: 2.19501\n",
      "Batch:208.0\n",
      "temp_loss: 0.77846\n",
      "Batch:209.0\n",
      "temp_loss: 1.84776\n",
      "Batch:210.0\n",
      "temp_loss: 0.709996\n",
      "Batch:211.0\n",
      "temp_loss: 1.25914\n",
      "Batch:212.0\n",
      "temp_loss: 0.694529\n",
      "Batch:213.0\n",
      "temp_loss: 1.04285\n",
      "Batch:214.0\n",
      "temp_loss: 0.73364\n",
      "Batch:215.0\n",
      "temp_loss: 1.107\n",
      "Batch:216.0\n",
      "temp_loss: 0.691344\n",
      "Batch:217.0\n",
      "temp_loss: 0.614388\n",
      "Batch:218.0\n",
      "temp_loss: 1.29861\n",
      "Batch:219.0\n",
      "temp_loss: 1.37579\n",
      "Batch:220.0\n",
      "temp_loss: 0.870041\n",
      "Batch:221.0\n",
      "temp_loss: 1.17222\n",
      "validating...\n",
      "validation loss:\n",
      "0.884654537439\n",
      "validation accuracy: \n",
      "0.505999985337\n",
      "Batch:222.0\n",
      "temp_loss: 0.729341\n",
      "Batch:223.0\n",
      "temp_loss: 0.760617\n",
      "Batch:224.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp_loss: 0.783945\n",
      "Batch:225.0\n",
      "temp_loss: 0.725758\n",
      "Batch:226.0\n",
      "temp_loss: 0.857333\n",
      "Batch:227.0\n",
      "temp_loss: 1.39544\n",
      "Batch:228.0\n",
      "temp_loss: 0.729454\n",
      "Batch:229.0\n",
      "temp_loss: 2.00008\n",
      "Batch:230.0\n",
      "temp_loss: 1.11661\n",
      "Batch:231.0\n",
      "temp_loss: 2.25217\n",
      "Batch:232.0\n",
      "temp_loss: 2.88344\n",
      "Batch:233.0\n",
      "temp_loss: 0.951568\n",
      "Batch:234.0\n",
      "temp_loss: 2.58563\n",
      "Batch:235.0\n",
      "temp_loss: 3.1486\n",
      "Batch:236.0\n",
      "temp_loss: 1.66331\n",
      "Batch:237.0\n",
      "temp_loss: 3.62902\n",
      "Batch:238.0\n",
      "temp_loss: 5.42438\n",
      "Batch:239.0\n",
      "temp_loss: 3.14602\n",
      "Batch:240.0\n",
      "temp_loss: 2.26248\n",
      "Batch:241.0\n",
      "temp_loss: 2.16899\n",
      "validating...\n",
      "validation loss:\n",
      "4.91188467264\n",
      "validation accuracy: \n",
      "0.505999985337\n",
      "Batch:242.0\n",
      "temp_loss: 4.35011\n",
      "Batch:243.0\n",
      "temp_loss: 4.55195\n",
      "Batch:244.0\n",
      "temp_loss: 2.26838\n",
      "Batch:245.0\n",
      "temp_loss: 2.32755\n",
      "Batch:246.0\n",
      "temp_loss: 3.16661\n",
      "Batch:247.0\n",
      "temp_loss: 2.29728\n",
      "Batch:248.0\n",
      "temp_loss: 1.19093\n",
      "Batch:249.0\n",
      "temp_loss: 2.72823\n",
      "Batch:250.0\n",
      "temp_loss: 0.734826\n",
      "Batch:251.0\n",
      "temp_loss: 2.6498\n",
      "Batch:252.0\n",
      "temp_loss: 2.6256\n",
      "Batch:253.0\n",
      "temp_loss: 0.716272\n",
      "Batch:254.0\n",
      "temp_loss: 2.69203\n",
      "Batch:255.0\n",
      "temp_loss: 1.5439\n",
      "Batch:256.0\n",
      "temp_loss: 2.47039\n",
      "Batch:257.0\n",
      "temp_loss: 1.14754\n",
      "Batch:258.0\n",
      "temp_loss: 0.762027\n",
      "Batch:259.0\n",
      "temp_loss: 1.11457\n",
      "Batch:260.0\n",
      "temp_loss: 0.713006\n",
      "Batch:261.0\n",
      "temp_loss: 0.955581\n",
      "validating...\n",
      "validation loss:\n",
      "1.13740025163\n",
      "validation accuracy: \n",
      "0.49399998188\n",
      "Batch:262.0\n",
      "temp_loss: 1.31255\n",
      "Batch:263.0\n",
      "temp_loss: 1.46773\n",
      "Batch:264.0\n",
      "temp_loss: 1.49589\n",
      "Batch:265.0\n",
      "temp_loss: 1.03369\n",
      "Batch:266.0\n",
      "temp_loss: 1.02437\n",
      "Batch:267.0\n",
      "temp_loss: 0.884865\n",
      "Batch:268.0\n",
      "temp_loss: 0.986448\n",
      "Batch:269.0\n",
      "temp_loss: 0.661986\n",
      "Batch:270.0\n",
      "temp_loss: 0.892761\n",
      "Batch:271.0\n",
      "temp_loss: 0.737289\n",
      "Batch:272.0\n",
      "temp_loss: 0.778834\n",
      "Batch:273.0\n",
      "temp_loss: 0.876113\n",
      "Batch:274.0\n",
      "temp_loss: 0.812044\n",
      "Batch:275.0\n",
      "temp_loss: 0.732241\n",
      "Batch:276.0\n",
      "temp_loss: 0.73542\n",
      "Batch:277.0\n",
      "temp_loss: 0.686058\n",
      "Batch:278.0\n",
      "temp_loss: 0.850052\n",
      "Batch:279.0\n",
      "temp_loss: 0.789792\n",
      "Batch:280.0\n",
      "temp_loss: 1.02555\n",
      "Batch:281.0\n",
      "temp_loss: 1.09906\n",
      "validating...\n",
      "validation loss:\n",
      "0.905735418797\n",
      "validation accuracy: \n",
      "0.505999985337\n",
      "Batch:282.0\n",
      "temp_loss: 1.04326\n",
      "Batch:283.0\n",
      "temp_loss: 1.5837\n",
      "Batch:284.0\n",
      "temp_loss: 1.48782\n",
      "Batch:285.0\n",
      "temp_loss: 1.20506\n",
      "Batch:286.0\n",
      "temp_loss: 2.01017\n",
      "Batch:287.0\n",
      "temp_loss: 1.63058\n",
      "Batch:288.0\n",
      "temp_loss: 1.78738\n",
      "Batch:289.0\n",
      "temp_loss: 0.76984\n",
      "Batch:290.0\n",
      "temp_loss: 2.37201\n",
      "Batch:291.0\n",
      "temp_loss: 1.65822\n",
      "Batch:292.0\n",
      "temp_loss: 1.58531\n",
      "Batch:293.0\n",
      "temp_loss: 2.46448\n",
      "Batch:294.0\n",
      "temp_loss: 1.26468\n",
      "Batch:295.0\n",
      "temp_loss: 2.51868\n",
      "Batch:296.0\n",
      "temp_loss: 2.71779\n",
      "Batch:297.0\n",
      "temp_loss: 0.799852\n",
      "Batch:298.0\n",
      "temp_loss: 1.14839\n",
      "Batch:299.0\n",
      "temp_loss: 1.20502\n",
      "Batch:300.0\n",
      "temp_loss: 0.89958\n",
      "Batch:301.0\n",
      "temp_loss: 1.22887\n",
      "validating...\n",
      "validation loss:\n",
      "0.715868533254\n",
      "validation accuracy: \n",
      "0.49399998188\n",
      "Batch:302.0\n",
      "temp_loss: 0.713443\n",
      "Batch:303.0\n",
      "temp_loss: 1.13345\n",
      "Batch:304.0\n",
      "temp_loss: 0.702252\n",
      "Batch:305.0\n",
      "temp_loss: 0.662435\n",
      "Batch:306.0\n",
      "temp_loss: 0.838634\n",
      "Batch:307.0\n",
      "temp_loss: 0.680461\n",
      "Batch:308.0\n",
      "temp_loss: 0.989252\n",
      "Batch:309.0\n",
      "temp_loss: 0.687633\n",
      "Batch:310.0\n",
      "temp_loss: 0.867691\n",
      "Batch:311.0\n",
      "temp_loss: 0.908663\n",
      "Batch:312.0\n",
      "temp_loss: 2.0979\n",
      "Batch:313.0\n",
      "temp_loss: 1.2131\n",
      "Batch:314.0\n",
      "temp_loss: 2.0819\n",
      "Batch:315.0\n",
      "temp_loss: 1.45344\n",
      "Batch:316.0\n",
      "temp_loss: 0.731638\n",
      "Batch:317.0\n",
      "temp_loss: 1.06698\n",
      "Batch:318.0\n",
      "temp_loss: 0.697825\n",
      "Batch:319.0\n",
      "temp_loss: 0.72779\n",
      "Batch:320.0\n",
      "temp_loss: 0.961255\n",
      "Batch:321.0\n",
      "temp_loss: 1.45775\n",
      "validating...\n",
      "validation loss:\n",
      "0.985459138155\n",
      "validation accuracy: \n",
      "0.49399998188\n",
      "Batch:322.0\n",
      "temp_loss: 1.02526\n",
      "Batch:323.0\n",
      "temp_loss: 1.72319\n",
      "Batch:324.0\n",
      "temp_loss: 1.23002\n",
      "Batch:325.0\n",
      "temp_loss: 2.34961\n",
      "Batch:326.0\n",
      "temp_loss: 2.58435\n",
      "Batch:327.0\n",
      "temp_loss: 1.28232\n",
      "Batch:328.0\n",
      "temp_loss: 1.25384\n",
      "Batch:329.0\n",
      "temp_loss: 0.99739\n",
      "Batch:330.0\n",
      "temp_loss: 0.944991\n",
      "Batch:331.0\n",
      "temp_loss: 1.0046\n",
      "Batch:332.0\n",
      "temp_loss: 0.841122\n",
      "Batch:333.0\n",
      "temp_loss: 1.01448\n",
      "Batch:334.0\n",
      "temp_loss: 1.17299\n",
      "Batch:335.0\n",
      "temp_loss: 1.18695\n",
      "Batch:336.0\n",
      "temp_loss: 0.747042\n",
      "Batch:337.0\n",
      "temp_loss: 0.603604\n",
      "Batch:338.0\n",
      "temp_loss: 1.24633\n",
      "Batch:339.0\n",
      "temp_loss: 0.718575\n",
      "Batch:340.0\n",
      "temp_loss: 1.2223\n",
      "Batch:341.0\n",
      "temp_loss: 0.964099\n",
      "validating...\n",
      "validation loss:\n",
      "1.03116174757\n",
      "validation accuracy: \n",
      "0.49399998188\n",
      "Batch:342.0\n",
      "temp_loss: 1.34135\n",
      "Batch:343.0\n",
      "temp_loss: 0.712898\n",
      "Batch:344.0\n",
      "temp_loss: 0.667626\n",
      "Batch:345.0\n",
      "temp_loss: 0.856737\n",
      "Batch:346.0\n",
      "temp_loss: 0.562648\n",
      "Batch:347.0\n",
      "temp_loss: 1.88677\n",
      "Batch:348.0\n",
      "temp_loss: 0.709845\n",
      "Batch:349.0\n",
      "temp_loss: 1.76069\n",
      "Batch:350.0\n",
      "temp_loss: 0.738163\n",
      "Batch:351.0\n",
      "temp_loss: 2.11879\n",
      "Batch:352.0\n",
      "temp_loss: 0.754729\n",
      "Batch:353.0\n",
      "temp_loss: 1.70564\n",
      "Batch:354.0\n",
      "temp_loss: 0.854748\n",
      "Batch:355.0\n",
      "temp_loss: 1.15262\n",
      "Batch:356.0\n",
      "temp_loss: 0.734576\n",
      "Batch:357.0\n",
      "temp_loss: 0.781378\n",
      "Batch:358.0\n",
      "temp_loss: 1.14989\n",
      "Batch:359.0\n",
      "temp_loss: 0.688526\n",
      "Batch:360.0\n",
      "temp_loss: 1.99031\n",
      "Batch:361.0\n",
      "temp_loss: 0.767972\n",
      "validating...\n",
      "validation loss:\n",
      "1.60898526669\n",
      "validation accuracy: \n",
      "0.505999985337\n",
      "Batch:362.0\n",
      "temp_loss: 1.62803\n",
      "Batch:363.0\n",
      "temp_loss: 0.691366\n",
      "Batch:364.0\n",
      "temp_loss: 1.31505\n",
      "Batch:365.0\n",
      "temp_loss: 0.839037\n",
      "Batch:366.0\n",
      "temp_loss: 1.493\n",
      "Batch:367.0\n",
      "temp_loss: 0.807474\n",
      "Batch:368.0\n",
      "temp_loss: 0.875474\n",
      "Batch:369.0\n",
      "temp_loss: 1.60843\n",
      "Batch:370.0\n",
      "temp_loss: 0.691305\n",
      "Batch:371.0\n",
      "temp_loss: 1.79682\n",
      "Batch:372.0\n",
      "temp_loss: 0.926414\n",
      "Batch:373.0\n",
      "temp_loss: 2.35627\n",
      "Batch:374.0\n",
      "temp_loss: 1.50504\n",
      "Batch:375.0\n",
      "temp_loss: 1.72481\n",
      "Batch:376.0\n",
      "temp_loss: 1.61863\n",
      "Batch:377.0\n",
      "temp_loss: 0.705271\n",
      "Batch:378.0\n",
      "temp_loss: 1.49398\n",
      "Batch:379.0\n",
      "temp_loss: 2.00464\n",
      "Batch:380.0\n",
      "temp_loss: 0.708164\n",
      "Batch:381.0\n",
      "temp_loss: 2.13594\n",
      "validating...\n",
      "validation loss:\n",
      "1.83316733837\n",
      "validation accuracy: \n",
      "0.505999985337\n",
      "Batch:382.0\n",
      "temp_loss: 1.74077\n",
      "Batch:383.0\n",
      "temp_loss: 0.897532\n",
      "Batch:384.0\n",
      "temp_loss: 1.37111\n",
      "Batch:385.0\n",
      "temp_loss: 0.738004\n",
      "Batch:386.0\n",
      "temp_loss: 0.863101\n",
      "Batch:387.0\n",
      "temp_loss: 0.86642\n",
      "Batch:388.0\n",
      "temp_loss: 1.64221\n",
      "Batch:389.0\n",
      "temp_loss: 1.46115\n",
      "Batch:390.0\n",
      "temp_loss: 1.36361\n",
      "Batch:391.0\n",
      "temp_loss: 2.05729\n",
      "Batch:392.0\n",
      "temp_loss: 0.68836\n",
      "Batch:393.0\n",
      "temp_loss: 1.95605\n",
      "Batch:394.0\n",
      "temp_loss: 1.28134\n",
      "Batch:395.0\n",
      "temp_loss: 1.70529\n",
      "Batch:396.0\n",
      "temp_loss: 1.7481\n",
      "Batch:397.0\n",
      "temp_loss: 0.696492\n",
      "Batch:398.0\n",
      "temp_loss: 1.73074\n",
      "Batch:399.0\n",
      "temp_loss: 1.10595\n",
      "Batch:400.0\n",
      "temp_loss: 1.15577\n",
      "Batch:401.0\n",
      "temp_loss: 2.18238\n",
      "validating...\n",
      "validation loss:\n",
      "0.785801021457\n",
      "validation accuracy: \n",
      "0.49399998188\n",
      "Batch:402.0\n",
      "temp_loss: 0.886857\n",
      "Batch:403.0\n",
      "temp_loss: 0.893318\n",
      "Batch:404.0\n",
      "temp_loss: 0.705463\n",
      "Batch:405.0\n",
      "temp_loss: 1.0782\n",
      "Batch:406.0\n",
      "temp_loss: 0.831414\n",
      "Batch:407.0\n",
      "temp_loss: 1.34728\n",
      "Batch:408.0\n",
      "temp_loss: 1.23745\n",
      "Batch:409.0\n",
      "temp_loss: 0.829544\n",
      "Batch:410.0\n",
      "temp_loss: 1.18649\n",
      "Batch:411.0\n",
      "temp_loss: 0.845441\n",
      "Batch:412.0\n",
      "temp_loss: 0.699266\n",
      "Batch:413.0\n",
      "temp_loss: 0.77276\n",
      "Batch:414.0\n",
      "temp_loss: 0.691705\n",
      "Batch:415.0\n",
      "temp_loss: 0.773428\n",
      "Batch:416.0\n",
      "temp_loss: 0.692369\n",
      "Batch:417.0\n",
      "temp_loss: 0.743076\n",
      "Batch:418.0\n",
      "temp_loss: 0.688289\n",
      "Batch:419.0\n",
      "temp_loss: 1.20834\n",
      "Batch:420.0\n",
      "temp_loss: 0.677898\n",
      "Batch:421.0\n",
      "temp_loss: 1.27958\n",
      "validating...\n",
      "validation loss:\n",
      "0.696777412891\n",
      "validation accuracy: \n",
      "0.49399998188\n",
      "Batch:422.0\n",
      "temp_loss: 0.672739\n",
      "Batch:423.0\n",
      "temp_loss: 0.806578\n",
      "Batch:424.0\n",
      "temp_loss: 0.734658\n",
      "Batch:425.0\n",
      "temp_loss: 0.709383\n",
      "Batch:426.0\n",
      "temp_loss: 0.675872\n",
      "Batch:427.0\n",
      "temp_loss: 0.784127\n",
      "Batch:428.0\n",
      "temp_loss: 0.663537\n",
      "Batch:429.0\n",
      "temp_loss: 0.671576\n",
      "Batch:430.0\n",
      "temp_loss: 0.839828\n",
      "Batch:431.0\n",
      "temp_loss: 0.728383\n",
      "Batch:432.0\n",
      "temp_loss: 1.31114\n",
      "Batch:433.0\n",
      "temp_loss: 0.928573\n",
      "Batch:434.0\n",
      "temp_loss: 0.920982\n",
      "Batch:435.0\n",
      "temp_loss: 1.27566\n",
      "Batch:436.0\n",
      "temp_loss: 1.54245\n",
      "Batch:437.0\n",
      "temp_loss: 0.698702\n",
      "Batch:438.0\n",
      "temp_loss: 0.888451\n",
      "Batch:439.0\n",
      "temp_loss: 0.784545\n",
      "Batch:440.0\n",
      "temp_loss: 0.938803\n",
      "Batch:441.0\n",
      "temp_loss: 0.821624\n",
      "validating...\n",
      "validation loss:\n",
      "1.33744619191\n",
      "validation accuracy: \n",
      "0.49399998188\n",
      "Batch:442.0\n",
      "temp_loss: 1.16722\n",
      "Batch:443.0\n",
      "temp_loss: 1.09996\n",
      "Batch:444.0\n",
      "temp_loss: 1.17674\n",
      "Batch:445.0\n",
      "temp_loss: 1.13376\n",
      "Batch:446.0\n",
      "temp_loss: 1.24757\n",
      "Batch:447.0\n",
      "temp_loss: 0.754488\n",
      "Batch:448.0\n",
      "temp_loss: 1.10326\n",
      "Batch:449.0\n",
      "temp_loss: 0.835658\n",
      "Batch:450.0\n",
      "temp_loss: 1.13509\n",
      "Batch:451.0\n",
      "temp_loss: 0.999786\n",
      "Batch:452.0\n",
      "temp_loss: 1.15533\n",
      "Batch:453.0\n",
      "temp_loss: 1.23614\n",
      "Batch:454.0\n",
      "temp_loss: 1.69756\n",
      "Batch:455.0\n",
      "temp_loss: 1.28925\n",
      "Batch:456.0\n",
      "temp_loss: 0.562405\n",
      "Batch:457.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp_loss: 2.1797\n",
      "Batch:458.0\n",
      "temp_loss: 2.07225\n",
      "Batch:459.0\n",
      "temp_loss: 1.4497\n",
      "Batch:460.0\n",
      "temp_loss: 2.39604\n",
      "Batch:461.0\n",
      "temp_loss: 1.14409\n",
      "validating...\n",
      "validation loss:\n",
      "2.43047957182\n",
      "validation accuracy: \n",
      "0.505999985337\n",
      "Batch:462.0\n",
      "temp_loss: 3.22633\n",
      "Batch:463.0\n",
      "temp_loss: 2.36922\n",
      "Batch:464.0\n",
      "temp_loss: 0.69742\n",
      "Batch:465.0\n",
      "temp_loss: 1.84782\n",
      "Batch:466.0\n",
      "temp_loss: 1.2081\n",
      "Batch:467.0\n",
      "temp_loss: 0.758348\n",
      "Batch:468.0\n",
      "temp_loss: 1.42497\n",
      "Batch:469.0\n",
      "temp_loss: 0.691323\n",
      "Batch:470.0\n",
      "temp_loss: 1.0966\n",
      "Batch:471.0\n",
      "temp_loss: 1.00295\n",
      "Batch:472.0\n",
      "temp_loss: 1.3233\n",
      "Batch:473.0\n",
      "temp_loss: 1.30607\n",
      "Batch:474.0\n",
      "temp_loss: 0.823052\n",
      "Batch:475.0\n",
      "temp_loss: 1.06856\n",
      "Batch:476.0\n",
      "temp_loss: 0.752671\n",
      "Batch:477.0\n",
      "temp_loss: 1.44194\n",
      "Batch:478.0\n",
      "temp_loss: 1.17181\n",
      "Batch:479.0\n",
      "temp_loss: 1.48302\n",
      "Batch:480.0\n",
      "temp_loss: 0.836378\n",
      "Batch:481.0\n",
      "temp_loss: 0.849858\n",
      "validating...\n",
      "validation loss:\n",
      "0.950897317529\n",
      "validation accuracy: \n",
      "0.505999985337\n",
      "Batch:482.0\n",
      "temp_loss: 0.864619\n",
      "Batch:483.0\n",
      "temp_loss: 0.753804\n",
      "Batch:484.0\n",
      "temp_loss: 0.913677\n",
      "Batch:485.0\n",
      "temp_loss: 0.7134\n",
      "Batch:486.0\n",
      "temp_loss: 1.33247\n",
      "Batch:487.0\n",
      "temp_loss: 0.796029\n",
      "Batch:488.0\n",
      "temp_loss: 0.976878\n",
      "Batch:489.0\n",
      "temp_loss: 0.727262\n",
      "Batch:490.0\n",
      "temp_loss: 1.78653\n",
      "Batch:491.0\n",
      "temp_loss: 0.727288\n",
      "Batch:492.0\n",
      "temp_loss: 1.20104\n",
      "Batch:493.0\n",
      "temp_loss: 1.2138\n",
      "Batch:494.0\n",
      "temp_loss: 1.33225\n",
      "Batch:495.0\n",
      "temp_loss: 1.03966\n",
      "Batch:496.0\n",
      "temp_loss: 0.821993\n",
      "Batch:497.0\n",
      "temp_loss: 0.742946\n",
      "Batch:498.0\n",
      "temp_loss: 0.869373\n",
      "Batch:499.0\n",
      "temp_loss: 1.60098\n",
      "Batch:500.0\n",
      "temp_loss: 1.22362\n",
      "Batch:501.0\n",
      "temp_loss: 1.53714\n",
      "validating...\n",
      "validation loss:\n",
      "2.21683799267\n",
      "validation accuracy: \n",
      "0.49399998188\n",
      "Batch:502.0\n",
      "temp_loss: 2.59907\n",
      "Batch:503.0\n",
      "temp_loss: 0.700235\n",
      "Batch:504.0\n",
      "temp_loss: 2.17661\n",
      "Batch:505.0\n",
      "temp_loss: 1.30189\n",
      "Batch:506.0\n",
      "temp_loss: 2.19623\n",
      "Batch:507.0\n",
      "temp_loss: 2.84332\n",
      "Batch:508.0\n",
      "temp_loss: 0.691996\n",
      "Batch:509.0\n",
      "temp_loss: 2.30317\n",
      "Batch:510.0\n",
      "temp_loss: 1.93203\n",
      "Batch:511.0\n",
      "temp_loss: 0.771425\n",
      "Batch:512.0\n",
      "temp_loss: 1.49471\n",
      "Batch:513.0\n",
      "temp_loss: 0.7478\n",
      "Batch:514.0\n",
      "temp_loss: 1.03192\n",
      "Batch:515.0\n",
      "temp_loss: 1.44119\n",
      "Batch:516.0\n",
      "temp_loss: 0.778357\n",
      "Batch:517.0\n",
      "temp_loss: 1.56481\n",
      "Batch:518.0\n",
      "temp_loss: 0.696045\n",
      "Batch:519.0\n",
      "temp_loss: 0.990067\n",
      "Batch:520.0\n",
      "temp_loss: 0.837232\n",
      "Batch:521.0\n",
      "temp_loss: 1.49139\n",
      "validating...\n",
      "validation loss:\n",
      "1.14723330259\n",
      "validation accuracy: \n",
      "0.49399998188\n",
      "Batch:522.0\n",
      "temp_loss: 1.00877\n",
      "Batch:523.0\n",
      "temp_loss: 1.18241\n",
      "Batch:524.0\n",
      "temp_loss: 0.80903\n",
      "Batch:525.0\n",
      "temp_loss: 0.935381\n",
      "Batch:526.0\n",
      "temp_loss: 1.16389\n",
      "Batch:527.0\n",
      "temp_loss: 1.55521\n",
      "Batch:528.0\n",
      "temp_loss: 1.19174\n",
      "Batch:529.0\n",
      "temp_loss: 1.03709\n",
      "Batch:530.0\n",
      "temp_loss: 1.11031\n",
      "Batch:531.0\n",
      "temp_loss: 1.14148\n",
      "Batch:532.0\n",
      "temp_loss: 0.805322\n",
      "Batch:533.0\n",
      "temp_loss: 1.01743\n",
      "Batch:534.0\n",
      "temp_loss: 1.22436\n",
      "Batch:535.0\n",
      "temp_loss: 1.413\n",
      "Batch:536.0\n",
      "temp_loss: 0.726969\n",
      "Batch:537.0\n",
      "temp_loss: 1.11698\n",
      "Batch:538.0\n",
      "temp_loss: 0.695603\n",
      "Batch:539.0\n",
      "temp_loss: 1.29322\n",
      "Batch:540.0\n",
      "temp_loss: 0.744369\n",
      "Batch:541.0\n",
      "temp_loss: 1.24829\n",
      "validating...\n",
      "validation loss:\n",
      "0.843412411809\n",
      "validation accuracy: \n",
      "0.505999985337\n",
      "Batch:542.0\n",
      "temp_loss: 0.994182\n",
      "Batch:543.0\n",
      "temp_loss: 0.770243\n",
      "Batch:544.0\n",
      "temp_loss: 1.19114\n",
      "Batch:545.0\n",
      "temp_loss: 0.860754\n",
      "Batch:546.0\n",
      "temp_loss: 1.1785\n",
      "Batch:547.0\n",
      "temp_loss: 0.820277\n",
      "Batch:548.0\n",
      "temp_loss: 1.0143\n",
      "Batch:549.0\n",
      "temp_loss: 0.665632\n",
      "Batch:550.0\n",
      "temp_loss: 0.750688\n",
      "Batch:551.0\n",
      "temp_loss: 0.714984\n",
      "Batch:552.0\n",
      "temp_loss: 0.720501\n",
      "Batch:553.0\n",
      "temp_loss: 0.857828\n",
      "Batch:554.0\n",
      "temp_loss: 0.723603\n",
      "Batch:555.0\n",
      "temp_loss: 0.788492\n",
      "Batch:556.0\n",
      "temp_loss: 0.91473\n",
      "Batch:557.0\n",
      "temp_loss: 0.704848\n",
      "Batch:558.0\n",
      "temp_loss: 1.01304\n",
      "Batch:559.0\n",
      "temp_loss: 0.840984\n",
      "Batch:560.0\n",
      "temp_loss: 1.12524\n",
      "Batch:561.0\n",
      "temp_loss: 1.23709\n",
      "validating...\n",
      "validation loss:\n",
      "1.15721530855\n",
      "validation accuracy: \n",
      "0.49399998188\n",
      "Batch:562.0\n",
      "temp_loss: 1.017\n",
      "Batch:563.0\n",
      "temp_loss: 1.37087\n",
      "Batch:564.0\n",
      "temp_loss: 0.65534\n",
      "Batch:565.0\n",
      "temp_loss: 2.18565\n",
      "Batch:566.0\n",
      "temp_loss: 1.05418\n",
      "Batch:567.0\n",
      "temp_loss: 1.33306\n",
      "Batch:568.0\n",
      "temp_loss: 1.66825\n",
      "Batch:569.0\n",
      "temp_loss: 0.751179\n",
      "Batch:570.0\n",
      "temp_loss: 2.28888\n",
      "Batch:571.0\n",
      "temp_loss: 0.859603\n",
      "Batch:572.0\n",
      "temp_loss: 0.848256\n",
      "Batch:573.0\n",
      "temp_loss: 1.67774\n",
      "Batch:574.0\n",
      "temp_loss: 0.69699\n",
      "Batch:575.0\n",
      "temp_loss: 1.33383\n",
      "Batch:576.0\n",
      "temp_loss: 1.11278\n",
      "Batch:577.0\n",
      "temp_loss: 1.23734\n",
      "Batch:578.0\n",
      "temp_loss: 1.83059\n",
      "Batch:579.0\n",
      "temp_loss: 1.1315\n",
      "Batch:580.0\n",
      "temp_loss: 1.77366\n",
      "Batch:581.0\n",
      "temp_loss: 1.95206\n",
      "validating...\n",
      "validation loss:\n",
      "1.13103636742\n",
      "validation accuracy: \n",
      "0.505999985337\n",
      "Batch:582.0\n",
      "temp_loss: 1.3348\n",
      "Batch:583.0\n",
      "temp_loss: 3.17106\n",
      "Batch:584.0\n",
      "temp_loss: 1.90416\n",
      "Batch:585.0\n",
      "temp_loss: 1.39666\n",
      "Batch:586.0\n",
      "temp_loss: 2.33873\n",
      "Batch:587.0\n",
      "temp_loss: 3.63645\n",
      "Batch:588.0\n",
      "temp_loss: 3.78462\n",
      "Batch:589.0\n",
      "temp_loss: 1.25644\n",
      "Batch:590.0\n",
      "temp_loss: 2.28535\n",
      "Batch:591.0\n",
      "temp_loss: 4.81685\n",
      "Batch:592.0\n",
      "temp_loss: 2.77286\n",
      "Batch:593.0\n",
      "temp_loss: 1.50569\n",
      "Batch:594.0\n",
      "temp_loss: 2.81496\n",
      "Batch:595.0\n",
      "temp_loss: 1.81196\n",
      "Batch:596.0\n",
      "temp_loss: 1.7576\n",
      "Batch:597.0\n",
      "temp_loss: 1.54219\n",
      "Batch:598.0\n",
      "temp_loss: 3.3801\n",
      "Batch:599.0\n",
      "temp_loss: 1.89922\n",
      "Batch:600.0\n",
      "temp_loss: 1.93311\n",
      "Batch:601.0\n",
      "temp_loss: 2.42046\n",
      "validating...\n",
      "validation loss:\n",
      "2.10522808075\n",
      "validation accuracy: \n",
      "0.505999985337\n",
      "Batch:602.0\n",
      "temp_loss: 2.52741\n",
      "Batch:603.0\n",
      "temp_loss: 1.08916\n",
      "Batch:604.0\n",
      "temp_loss: 2.44804\n",
      "Batch:605.0\n",
      "temp_loss: 3.14109\n",
      "Batch:606.0\n",
      "temp_loss: 1.11666\n",
      "Batch:607.0\n",
      "temp_loss: 3.24545\n",
      "Batch:608.0\n",
      "temp_loss: 1.74545\n",
      "Batch:609.0\n",
      "temp_loss: 1.30156\n",
      "Batch:610.0\n",
      "temp_loss: 4.34753\n",
      "Batch:611.0\n",
      "temp_loss: 2.09327\n",
      "Batch:612.0\n",
      "temp_loss: 1.05662\n",
      "Batch:613.0\n",
      "temp_loss: 2.29466\n",
      "Batch:614.0\n",
      "temp_loss: 1.11869\n",
      "Batch:615.0\n",
      "temp_loss: 2.15828\n",
      "Batch:616.0\n",
      "temp_loss: 1.88016\n",
      "Batch:617.0\n",
      "temp_loss: 1.10787\n",
      "Batch:618.0\n",
      "temp_loss: 2.05539\n",
      "Batch:619.0\n",
      "temp_loss: 0.779979\n",
      "Batch:620.0\n",
      "temp_loss: 1.48637\n",
      "Batch:621.0\n",
      "temp_loss: 0.68847\n",
      "validating...\n",
      "validation loss:\n",
      "1.43096807003\n",
      "validation accuracy: \n",
      "0.505999985337\n",
      "Batch:622.0\n",
      "temp_loss: 1.36092\n",
      "Batch:623.0\n",
      "temp_loss: 1.04651\n",
      "Batch:624.0\n",
      "temp_loss: 1.35705\n",
      "Batch:625.0\n",
      "temp_loss: 1.31359\n",
      "processing epoch 1\n",
      "total number of batches in 1 epoch: 625.0\n",
      "Batch:1.0\n",
      "temp_loss: 0.802083\n",
      "Batch:2.0\n",
      "temp_loss: 0.672695\n",
      "Batch:3.0\n",
      "temp_loss: 0.781801\n",
      "Batch:4.0\n",
      "temp_loss: 0.931733\n",
      "Batch:5.0\n",
      "temp_loss: 0.718947\n",
      "Batch:6.0\n",
      "temp_loss: 0.720264\n",
      "Batch:7.0\n",
      "temp_loss: 0.837588\n",
      "Batch:8.0\n",
      "temp_loss: 0.847644\n",
      "Batch:9.0\n",
      "temp_loss: 0.743371\n",
      "Batch:10.0\n",
      "temp_loss: 0.814105\n",
      "Batch:11.0\n",
      "temp_loss: 0.691501\n",
      "Batch:12.0\n",
      "temp_loss: 0.686159\n",
      "Batch:13.0\n",
      "temp_loss: 0.815151\n",
      "Batch:14.0\n",
      "temp_loss: 0.766882\n",
      "Batch:15.0\n",
      "temp_loss: 0.862173\n",
      "Batch:16.0\n",
      "temp_loss: 0.675603\n",
      "Batch:17.0\n",
      "temp_loss: 0.693298\n",
      "Batch:18.0\n",
      "temp_loss: 0.645806\n",
      "Batch:19.0\n",
      "temp_loss: 0.764952\n",
      "Batch:20.0\n",
      "temp_loss: 0.647606\n",
      "Batch:21.0\n",
      "temp_loss: 0.746729\n",
      "Batch:22.0\n",
      "temp_loss: 0.803123\n",
      "Batch:23.0\n",
      "temp_loss: 0.783759\n",
      "Batch:24.0\n",
      "temp_loss: 0.686988\n",
      "Batch:25.0\n",
      "temp_loss: 0.693891\n",
      "Batch:26.0\n",
      "temp_loss: 0.729749\n",
      "Batch:27.0\n",
      "temp_loss: 0.732003\n",
      "Batch:28.0\n",
      "temp_loss: 0.802783\n",
      "Batch:29.0\n",
      "temp_loss: 0.806727\n",
      "Batch:30.0\n",
      "temp_loss: 0.74651\n",
      "Batch:31.0\n",
      "temp_loss: 0.69331\n",
      "Batch:32.0\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "start_learning_rate = 0.01\n",
    "batch = tf.Variable(0, trainable=False)\n",
    "train_size = 20000\n",
    "val_size = 5000\n",
    "learning_rate = tf.train.exponential_decay(\n",
    "  0.001,                # Base learning rate.\n",
    "  batch * BATCH_SIZE,  # Current index into the dataset.\n",
    "  train_size,          # Decay step.\n",
    "  0.1,                # Decay rate.\n",
    "  staircase=True)\n",
    "\n",
    "\n",
    "with tf.name_scope('inputs'):\n",
    "    X = tf.placeholder(tf.float32, shape=(None,IMG_SIZE,IMG_SIZE , 3),name=\"X\")\n",
    "    tf.summary.image('input', X, BATCH_SIZE)\n",
    "    Y = tf.placeholder(tf.float32,shape=(None,2),name=\"labels\")\n",
    "    \n",
    "logits = vggnet_v1(X)\n",
    "with tf.name_scope(\"loss\"):    \n",
    "    train_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y), name=\"loss\")\n",
    "    tf.summary.scalar(\"loss\", train_loss)\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    #optimizer = tf.train.MomentumOptimizer(learning_rate, 0.9).minimize(train_loss)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(train_loss,global_step=batch)\n",
    "print(\"optimizer set\")\n",
    "\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)\n",
    "print(\"accuracy set\")\n",
    "\n",
    "merged_summary = tf.summary.merge_all()\n",
    "\n",
    "# init = \n",
    "# print(\"initializing the variables\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(\"session created.\")\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    print(\"writing tensorboard\")\n",
    "    writer = tf.summary.FileWriter(\"/tmp/tensorboard/cat-dog-vgg1\")\n",
    "    writer.add_graph(sess.graph)\n",
    "    print(\"writer added to graph\")\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        print(\"processing epoch \"+str(epoch))\n",
    "        print(\"total number of batches in 1 epoch: \"+ str(len(train_data)/BATCH_SIZE))\n",
    "        \n",
    "        for i in range(0,train_size,BATCH_SIZE): \n",
    "            #print(i)\n",
    "            print(\"Batch:\" + str((i/BATCH_SIZE)+1))\n",
    "            \n",
    "            #minibatch_X, minibatch_Y = prepare_data(train_data[i:i+BATCH_SIZE])\n",
    "            #sess.run(optimizer,feed_dict={X:minibatch_X,Y:minibatch_Y})\n",
    "            minibatch_X = train_X[i : i + BATCH_SIZE]\n",
    "            minibatch_Y = train_Y[i : i + BATCH_SIZE]\n",
    "            _ , temp_loss, temp_accuracy = sess.run([optimizer,train_loss,accuracy],feed_dict={X:minibatch_X,Y:minibatch_Y})\n",
    "            \n",
    "            if i % (BATCH_SIZE*10) == 0 and i >200:  # Record summaries and test-set accuracy\n",
    "                summary = sess.run(merged_summary, feed_dict={X:minibatch_X,Y:minibatch_Y})\n",
    "                writer.add_summary(summary, i + epoch*len(train_data))\n",
    "            \n",
    "            #writer.add_summary(summary, i)\n",
    "            print(\"temp_loss: \"+str(temp_loss))\n",
    "            \n",
    "            if i % (BATCH_SIZE*50) == 0 and i>=1000:\n",
    "                print(\"validating...\")\n",
    "                val_loss = 0\n",
    "                val_accuracy = 0\n",
    "                val_batch_size = 50\n",
    "                val_batches = val_size/val_batch_size\n",
    "                for v in range(0,val_size,val_batch_size):\n",
    "                    #val_x,val_y = prepare_data(val_data[v:v+BATCH_SIZE])\n",
    "                    val_minibatch_x = val_X[v : v + val_batch_size]\n",
    "                    val_minibatch_y = val_Y[v : v + val_batch_size]\n",
    "                    temp_loss, temp_accuracy = sess.run([train_loss,accuracy],feed_dict={X:val_minibatch_x,Y:val_minibatch_y})\n",
    "                    val_accuracy+=temp_accuracy\n",
    "                    val_loss+=temp_loss\n",
    "                print(\"validation loss:\")\n",
    "                print(val_loss/val_batches)\n",
    "                print(\"validation accuracy: \")\n",
    "                print(val_accuracy/val_batches)\n",
    "#             print(\"temp_accuracy: \"+str(temp_accuracy))\n",
    "#     train_accuracy = accuracy.eval({X: train_data, Y: train_labels})\n",
    "#     val_data, val_labels = prepare_data(val_data)\n",
    "#     val_accuracy = accuracy.eval({X: val_data, Y: val_labels})\n",
    "# #     print(\"Train Accuracy:\", train_accuracy)\n",
    "#     print(\"Validation Accuracy:\", val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
