{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "# import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import json\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# %matplotlib inline\n",
    "# np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = 224\n",
    "data_file = \"dataset.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_file =\"vgg16_weights.npz\"\n",
    "weights = np.load(weight_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = sorted(weights.keys())\n",
    "# for index, key in enumerate(keys):\n",
    "#     print(index, key, np.shape(weights[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_layer(input_data,filter_size,stride_size,pad=\"SAME\",name=\"conv\",weight_name=\"W1\",bias_name=\"b1\"):\n",
    "    print(\"creating layer :\"+name)\n",
    "    with tf.name_scope(name):\n",
    "        W = tf.Variable(weights[name+\"_W\"],name=\"weight\")\n",
    "        b = tf.Variable(weights[name+\"_b\"],name=\"bias\")\n",
    "        \n",
    "        conv = tf.nn.conv2d(input_data, W, strides=stride_size, padding=pad)\n",
    "        out = tf.nn.bias_add(conv, b)\n",
    "        act = tf.nn.relu(out)\n",
    "        tf.summary.histogram(\"weights\", W)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        tf.summary.histogram(\"activations\", act)\n",
    "        return act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vggnet_v1(input_data):\n",
    "    print(\"creating model\")\n",
    "    output=[]\n",
    "    layer_input = input_data\n",
    "    \n",
    "    with tf.name_scope('preprocess') as scope:\n",
    "        mean = tf.constant([123.68, 116.779, 103.939], dtype=tf.float32, shape=[1, 1, 1, 3], name='img_mean')\n",
    "        layer_input = layer_input-mean\n",
    "            \n",
    "    print(\"reading vgg16 json file\")\n",
    "    vgg = json.load(open(\"vgg16.json\"),object_pairs_hook=OrderedDict)\n",
    "       \n",
    "    for index,layer in enumerate(vgg):\n",
    "        if \"conv\" in layer:\n",
    "            output = conv_layer(layer_input,vgg[layer][\"weights\"],vgg[layer][\"stride\"],vgg[layer][\"pad\"],layer,\"weight\"+str(index),\"bias\"+str(index))\n",
    "        elif \"pool\" in layer:\n",
    "            output = tf.nn.max_pool(layer_input, ksize=vgg[layer][\"ksize\"], strides=vgg[layer][\"strides\"], padding=vgg[layer][\"padding\"],name=layer)\n",
    "        layer_input = output\n",
    "    \n",
    "    pool5_flat = tf.contrib.layers.flatten(output)\n",
    "\n",
    "    print(\"creating layer : fc6\")\n",
    "    with tf.name_scope('fc6'):\n",
    "        fc6_W = tf.Variable(weights[\"fc6_W\"],name=\"fc6_W\")\n",
    "        fc6_b= tf.Variable(weights[\"fc6_b\"],name=\"fc6_b\")\n",
    "\n",
    "        fc6 = tf.nn.bias_add(tf.matmul(pool5_flat, fc6_W), fc6_b)\n",
    "        fc6 = tf.nn.relu(fc6)\n",
    "    \n",
    "#     fc6 = tf.contrib.layers.fully_connected(P3,4096, weights_initializer=fc6_W, biases_initializer=fc6_b, scope=\"fc6\")\n",
    "    tf.summary.histogram(\"fc6/relu\", fc6)\n",
    "    \n",
    "    dropout1 = tf.layers.dropout(inputs=fc6, rate=0.5)\n",
    "\n",
    "    print(\"creating layer : fc7\")\n",
    "    with tf.name_scope('fc7'):\n",
    "        fc7_W = tf.Variable(weights[\"fc7_W\"],name=\"fc7_W\")\n",
    "        fc7_b= tf.Variable(weights[\"fc7_b\"],name=\"fc7_b\")\n",
    "\n",
    "        fc7 = tf.nn.bias_add(tf.matmul(dropout1, fc7_W), fc7_b)\n",
    "        fc7 = tf.nn.relu(fc7)\n",
    "    \n",
    "#     fc7 = tf.contrib.layers.fully_connected(dropout1,4096, weights_initializer=fc7_W, biases_initializer=fc7_b, scope=\"fc7\")\n",
    "    tf.summary.histogram(\"fc7/relu\", fc7)\n",
    "    \n",
    "    dropout2 = tf.layers.dropout(inputs=fc7, rate=0.5)\n",
    "    \n",
    "    print(\"creating layer : fc8\")\n",
    "    fc8 = tf.contrib.layers.fully_connected(dropout2,2, biases_initializer=tf.constant_initializer(1.0), activation_fn=None, scope=\"fc8\")\n",
    "    tf.summary.histogram(\"fc8\", fc8)\n",
    "    \n",
    "    \n",
    "    print(\"model completed.\")\n",
    "    ##NEED FULLY CONNECTED LAYER\n",
    "    return fc8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 123.68   116.779  103.939]]]]\n"
     ]
    }
   ],
   "source": [
    "mean = np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3))\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    newData=[]\n",
    "    labels=[]\n",
    "    print(\"preparing data....\")\n",
    "    for sample in data:\n",
    "        img_path,label = sample.strip().split(\" \")\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img,(IMG_SIZE,IMG_SIZE))\n",
    "        #img = Image.open(img_path)\n",
    "        #img = img.resize((IMG_SIZE,IMG_SIZE))\n",
    "        img = np.array(img)\n",
    "        #img = img/255\n",
    "        newData.append(img)\n",
    "        if \"cat\" in img_path:\n",
    "            labels.append(np.array([1,0]))\n",
    "        elif \"dog\" in img_path:\n",
    "            labels.append(np.array([0,1]))\n",
    "    print(\"preparing data completed.\")\n",
    "    return np.array(newData),np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "preparing data....\n",
      "preparing data completed.\n",
      "preparing data....\n",
      "preparing data completed.\n"
     ]
    }
   ],
   "source": [
    "f = open(data_file,\"r\")\n",
    "data = f.readlines()\n",
    "random.shuffle(data)\n",
    "print(len(data))\n",
    "train_data = data[:20000]\n",
    "train_X, train_Y = prepare_data(train_data)\n",
    "val_data = data[20000:]\n",
    "val_X, val_Y = prepare_data(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_X = train_X - mean\n",
    "# val_X = val_X - mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating model\n",
      "reading vgg16 json file\n",
      "creating layer :conv1_1\n",
      "creating layer :conv1_2\n",
      "creating layer :conv2_1\n",
      "creating layer :conv2_2\n",
      "creating layer :conv3_1\n",
      "creating layer :conv3_2\n",
      "creating layer :conv3_3\n",
      "creating layer :conv4_1\n",
      "creating layer :conv4_2\n",
      "creating layer :conv4_3\n",
      "creating layer :conv5_1\n",
      "creating layer :conv5_2\n",
      "creating layer :conv5_3\n",
      "creating layer : fc6\n",
      "creating layer : fc7\n",
      "creating layer : fc8\n",
      "model completed.\n",
      "optimizer set\n",
      "accuracy set\n",
      "session created.\n",
      "initializing global variables\n",
      "writing tensorboard\n",
      "writer added to graph\n",
      "processing epoch 0\n",
      "total number of batches in 1 epoch: 625.0\n",
      "i: 0\n",
      "Iteration:1.0\n",
      "temp_loss: 2.33953\n",
      "i: 32\n",
      "Iteration:2.0\n",
      "temp_loss: 127.545\n",
      "i: 64\n",
      "Iteration:3.0\n",
      "temp_loss: 294.963\n",
      "i: 96\n",
      "Iteration:4.0\n",
      "temp_loss: 15.9853\n",
      "i: 128\n",
      "Iteration:5.0\n",
      "temp_loss: 480.616\n",
      "i: 160\n",
      "Iteration:6.0\n",
      "temp_loss: 5.60068\n",
      "i: 192\n",
      "Iteration:7.0\n",
      "temp_loss: 1.83533\n",
      "i: 224\n",
      "Iteration:8.0\n",
      "temp_loss: 13.0807\n",
      "i: 256\n",
      "Iteration:9.0\n",
      "temp_loss: 2.59038\n",
      "i: 288\n",
      "Iteration:10.0\n",
      "temp_loss: 3.27843\n",
      "i: 320\n",
      "Iteration:11.0\n",
      "temp_loss: 2.07836\n",
      "i: 352\n",
      "Iteration:12.0\n",
      "temp_loss: 2.8079\n",
      "i: 384\n",
      "Iteration:13.0\n",
      "temp_loss: 1.97617\n",
      "i: 416\n",
      "Iteration:14.0\n",
      "temp_loss: 1.91818\n",
      "i: 448\n",
      "Iteration:15.0\n",
      "temp_loss: 2.19155\n",
      "i: 480\n",
      "Iteration:16.0\n",
      "temp_loss: 9.87996\n",
      "i: 512\n",
      "Iteration:17.0\n",
      "temp_loss: 0.674872\n",
      "i: 544\n",
      "Iteration:18.0\n",
      "temp_loss: 1.22341\n",
      "i: 576\n",
      "Iteration:19.0\n",
      "temp_loss: 0.716707\n",
      "i: 608\n",
      "Iteration:20.0\n",
      "temp_loss: 0.876237\n",
      "i: 640\n",
      "Iteration:21.0\n",
      "temp_loss: 0.631256\n",
      "i: 672\n",
      "Iteration:22.0\n",
      "temp_loss: 0.82216\n",
      "i: 704\n",
      "Iteration:23.0\n",
      "temp_loss: 0.674038\n",
      "i: 736\n",
      "Iteration:24.0\n",
      "temp_loss: 0.903097\n",
      "i: 768\n",
      "Iteration:25.0\n",
      "temp_loss: 0.782098\n",
      "i: 800\n",
      "Iteration:26.0\n",
      "temp_loss: 0.694612\n",
      "i: 832\n",
      "Iteration:27.0\n",
      "temp_loss: 0.737707\n",
      "i: 864\n",
      "Iteration:28.0\n",
      "temp_loss: 0.870912\n",
      "i: 896\n",
      "Iteration:29.0\n",
      "temp_loss: 0.674884\n",
      "i: 928\n",
      "Iteration:30.0\n",
      "temp_loss: 0.704234\n",
      "i: 960\n",
      "Iteration:31.0\n",
      "temp_loss: 0.865316\n",
      "i: 992\n",
      "Iteration:32.0\n",
      "temp_loss: 0.801201\n",
      "i: 1024\n",
      "Iteration:33.0\n",
      "temp_loss: 0.73753\n",
      "i: 1056\n",
      "Iteration:34.0\n",
      "temp_loss: 0.689259\n",
      "i: 1088\n",
      "Iteration:35.0\n",
      "temp_loss: 0.653599\n",
      "i: 1120\n",
      "Iteration:36.0\n",
      "temp_loss: 0.676504\n",
      "i: 1152\n",
      "Iteration:37.0\n",
      "temp_loss: 0.650176\n",
      "i: 1184\n",
      "Iteration:38.0\n",
      "temp_loss: 0.69733\n",
      "i: 1216\n",
      "Iteration:39.0\n",
      "temp_loss: 0.746569\n",
      "i: 1248\n",
      "Iteration:40.0\n",
      "temp_loss: 0.720752\n",
      "i: 1280\n",
      "Iteration:41.0\n",
      "temp_loss: 0.645132\n",
      "i: 1312\n",
      "Iteration:42.0\n",
      "temp_loss: 0.762653\n",
      "i: 1344\n",
      "Iteration:43.0\n",
      "temp_loss: 0.742203\n",
      "i: 1376\n",
      "Iteration:44.0\n",
      "temp_loss: 0.689733\n",
      "i: 1408\n",
      "Iteration:45.0\n",
      "temp_loss: 0.678711\n",
      "i: 1440\n",
      "Iteration:46.0\n",
      "temp_loss: 0.648025\n",
      "i: 1472\n",
      "Iteration:47.0\n",
      "temp_loss: 0.696564\n",
      "i: 1504\n",
      "Iteration:48.0\n",
      "temp_loss: 0.888082\n",
      "i: 1536\n",
      "Iteration:49.0\n",
      "temp_loss: 0.670612\n",
      "i: 1568\n",
      "Iteration:50.0\n",
      "temp_loss: 0.742151\n",
      "i: 1600\n",
      "Iteration:51.0\n",
      "temp_loss: 0.683988\n",
      "validating...\n",
      "val_loss: \n",
      "0.764270017743\n",
      "val_accuracy: \n",
      "0.531399984062\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'inputs/X' with dtype float and shape [?,224,224,3]\n\t [[Node: inputs/X = Placeholder[dtype=DT_FLOAT, shape=[?,224,224,3], _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\t [[Node: inputs/X/_245 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_280_inputs/X\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'inputs/X', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-63a02ae6269d>\", line 17, in <module>\n    X = tf.placeholder(tf.float32, shape=(None,IMG_SIZE,IMG_SIZE , 3),name=\"X\")\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py\", line 1548, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 2094, in _placeholder\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'inputs/X' with dtype float and shape [?,224,224,3]\n\t [[Node: inputs/X = Placeholder[dtype=DT_FLOAT, shape=[?,224,224,3], _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\t [[Node: inputs/X/_245 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_280_inputs/X\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'inputs/X' with dtype float and shape [?,224,224,3]\n\t [[Node: inputs/X = Placeholder[dtype=DT_FLOAT, shape=[?,224,224,3], _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\t [[Node: inputs/X/_245 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_280_inputs/X\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-63a02ae6269d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                 \u001b[0mval_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_summary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m                 \u001b[0mval_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_summary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'inputs/X' with dtype float and shape [?,224,224,3]\n\t [[Node: inputs/X = Placeholder[dtype=DT_FLOAT, shape=[?,224,224,3], _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\t [[Node: inputs/X/_245 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_280_inputs/X\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'inputs/X', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-63a02ae6269d>\", line 17, in <module>\n    X = tf.placeholder(tf.float32, shape=(None,IMG_SIZE,IMG_SIZE , 3),name=\"X\")\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py\", line 1548, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 2094, in _placeholder\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'inputs/X' with dtype float and shape [?,224,224,3]\n\t [[Node: inputs/X = Placeholder[dtype=DT_FLOAT, shape=[?,224,224,3], _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\t [[Node: inputs/X/_245 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_280_inputs/X\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "start_learning_rate = 0.01\n",
    "\n",
    "batch = tf.Variable(0, trainable=False)\n",
    "train_size = 20000\n",
    "val_size = 5000\n",
    "\n",
    "learning_rate = tf.train.exponential_decay(\n",
    "  0.001,                # Base learning rate.\n",
    "  batch * BATCH_SIZE,  # Current index into the dataset.\n",
    "  train_size,          # Decay step.\n",
    "  0.1,                # Decay rate.\n",
    "  staircase=True)\n",
    "\n",
    "with tf.name_scope('inputs'):\n",
    "    X = tf.placeholder(tf.float32, shape=(None,IMG_SIZE,IMG_SIZE , 3),name=\"X\")\n",
    "    tf.summary.image('input', X, BATCH_SIZE)\n",
    "    Y = tf.placeholder(tf.float32,shape=(None,2),name=\"labels\")\n",
    "    \n",
    "logits = vggnet_v1(X)\n",
    "\n",
    "with tf.name_scope(\"loss\"):    \n",
    "    train_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y), name=\"loss\")\n",
    "    tf.summary.scalar(\"loss\", train_loss)\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    #optimizer = tf.train.MomentumOptimizer(learning_rate, 0.9).minimize(train_loss)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(train_loss,global_step=batch)\n",
    "print(\"optimizer set\")\n",
    "\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)\n",
    "print(\"accuracy set\")\n",
    "\n",
    "val_loss = tf.Variable(0.0)\n",
    "tf.summary.scalar(\"loss\", val_loss)\n",
    "\n",
    "val_accuracy = tf.Variable(0.0)\n",
    "tf.summary.scalar(\"accuracy\", val_accuracy)\n",
    "\n",
    "\n",
    "merged_summary = tf.summary.merge_all()\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(\"session created.\")\n",
    "    print(\"initializing global variables\")\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    print(\"writing tensorboard\")\n",
    "    train_writer = tf.summary.FileWriter(\"/tmp/tensorboard/cat-dog-vgg-train\",sess.graph)\n",
    "    val_writer = tf.summary.FileWriter(\"/tmp/tensorboard/cat-dog-vgg-val\",sess.graph)\n",
    "\n",
    "    \n",
    "    print(\"writer added to graph\")\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        print(\"processing epoch \"+str(epoch))\n",
    "        print(\"total number of batches in 1 epoch: \"+ str(len(train_data)/BATCH_SIZE))\n",
    "        \n",
    "        for i in range(0,train_size,BATCH_SIZE): \n",
    "            print(\"i: \"+str(i))\n",
    "            print(\"Iteration:\" + str((i/BATCH_SIZE)+1))\n",
    "            \n",
    "            #minibatch_X, minibatch_Y = prepare_data(train_data[i:i+BATCH_SIZE])\n",
    "            #sess.run(optimizer,feed_dict={X:minibatch_X,Y:minibatch_Y})\n",
    "            \n",
    "            minibatch_X = train_X[i : i + BATCH_SIZE]\n",
    "            minibatch_Y = train_Y[i : i + BATCH_SIZE]\n",
    "            \n",
    "            _ , temp_loss, temp_accuracy = sess.run([optimizer,train_loss,accuracy],feed_dict={X:minibatch_X,Y:minibatch_Y})\n",
    "            \n",
    "            if i % (BATCH_SIZE*10) == 0 and i >200: \n",
    "                summary = sess.run(merged_summary,feed_dict={X:minibatch_X,Y:minibatch_Y})\n",
    "                train_writer.add_summary(summary, i + epoch*len(train_data))\n",
    "            \n",
    "            \n",
    "            \n",
    "            print(\"temp_loss: \"+str(temp_loss))\n",
    "            \n",
    "            if i % (BATCH_SIZE*50) == 0 and i>=1000:\n",
    "                print(\"validating...\")\n",
    "                total_loss = 0\n",
    "                total_accuracy = 0\n",
    "                val_batch_size = 50\n",
    "                val_batches = val_size/val_batch_size\n",
    "                for v in range(0,val_size,val_batch_size):\n",
    "                    #val_x,val_y = prepare_data(val_data[v:v+BATCH_SIZE])\n",
    "                    \n",
    "                    val_minibatch_x = val_X[v : v + val_batch_size]\n",
    "                    val_minibatch_y = val_Y[v : v + val_batch_size]\n",
    "                    temp_loss, temp_accuracy = sess.run([train_loss,accuracy],feed_dict={X:val_minibatch_x,Y:val_minibatch_y})\n",
    "                    total_accuracy+=temp_accuracy\n",
    "                    total_loss+=temp_loss\n",
    "                \n",
    "                val_loss = total_loss/val_batches\n",
    "                print(\"val_loss: \")\n",
    "                print(val_loss)\n",
    "                \n",
    "                val_accuracy = total_accuracy/val_batches\n",
    "                print(\"val_accuracy: \")\n",
    "                print(val_accuracy)\n",
    "                \n",
    "                val_summary = sess.run(merged_summary)\n",
    "                val_writer.add_summary(val_summary, i + epoch*len(train_data))\n",
    "\n",
    "                \n",
    "                \n",
    "\n",
    "#     train_accuracy = accuracy.eval({X: train_data, Y: train_labels})\n",
    "#     val_data, val_labels = prepare_data(val_data)\n",
    "#     val_accuracy = accuracy.eval({X: val_data, Y: val_labels})\n",
    "# #     print(\"Train Accuracy:\", train_accuracy)\n",
    "#     print(\"Validation Accuracy:\", val_accuracy)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
